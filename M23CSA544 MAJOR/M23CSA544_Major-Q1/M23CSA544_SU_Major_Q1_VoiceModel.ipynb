{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Voice Modelling using Tortoise-TTS***\n",
        "### ***By Lt Col Ritesh Lamba***"
      ],
      "metadata": {
        "id": "cUlakm1gqzxP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olyX1-kEGfpg"
      },
      "source": [
        "# Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PTK2b-fHFlzE",
        "outputId": "00fca166-4472-4b99-f876-c25dc2a9f8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tortoise-tts>=3.0.0 in /usr/local/lib/python3.11/dist-packages (3.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (4.67.1)\n",
            "Requirement already satisfied: rotary-embedding-torch in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (0.8.6)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (7.5.0)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (2.5)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (0.8.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (1.3.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (1.14.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (0.11.0)\n",
            "Requirement already satisfied: transformers==4.31.0 in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (4.31.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from tortoise-tts>=3.0.0) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.31.0->tortoise-tts>=3.0.0) (0.5.3)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect->tortoise-tts>=3.0.0) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->tortoise-tts>=3.0.0) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->tortoise-tts>=3.0.0) (1.1.0)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from rotary-embedding-torch->tortoise-tts>=3.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0->tortoise-tts>=3.0.0) (2025.3.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->tortoise-tts>=3.0.0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->tortoise-tts>=3.0.0) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->tortoise-tts>=3.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->tortoise-tts>=3.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->tortoise-tts>=3.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.31.0->tortoise-tts>=3.0.0) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->tortoise-tts>=3.0.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->tortoise-tts>=3.0.0) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tortoise-tts>=3.0.0) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->rotary-embedding-torch->tortoise-tts>=3.0.0) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"tortoise-tts>=3.0.0\"\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torchaudio\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_voice\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "device = \"Cuda\" if torch.cuda.is_available() else \"CPU\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svQ8mDycG0LA"
      },
      "source": [
        "# TTS - Generate Audio in own Voice (Transfer Learning / Speaker Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title FUNCTION TO SPLIT THE TEXT INTO SMALLER CHUNKS\n",
        "def split_text(text, max_words=400):\n",
        "    # Break into sentences/phrases based on punctuation\n",
        "    sentences = re.split(r'(?<=[।.?!])\\s+', text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_len = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        word_count = len(sentence.split())\n",
        "        if current_len + word_count <= max_words:\n",
        "            current_chunk.append(sentence)\n",
        "            current_len += word_count\n",
        "        else:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [sentence]\n",
        "            current_len = word_count\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "m63R7R_0ErmH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DOWNLOAD THE TRANSCRIPT & SAMPLE AUDIO FILE\n",
        "# https://drive.google.com/file/d/1ahUfB4E4j3eJvZ5bR3G02ilm36lJwD5r/view?usp=sharing\n",
        "# Download recorded voice sample from Google Drive using file ID\n",
        "file_id = \"1ahUfB4E4j3eJvZ5bR3G02ilm36lJwD5r\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "original_sample_path = \"original_sample.wav\"\n",
        "gdown.download(url, original_sample_path, quiet=False)\n",
        "assert os.path.exists(\"original_sample.wav\"), \"WAV file not found!\"\n",
        "\n",
        "# https://drive.google.com/file/d/1x-AYvELvfmI_3h5bajLbECTKuPgBOBIB/view?usp=sharing\n",
        "# Download hindi transcript generated from Google Drive using file ID\n",
        "file_id = \"1x-AYvELvfmI_3h5bajLbECTKuPgBOBIB\"\n",
        "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "hindi_transcript = \"hindi_transcript.txt\"\n",
        "gdown.download(url, hindi_transcript, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "mfJOdlpwE-ls",
        "outputId": "835cea2a-caf3-4dba-c47c-ba9c398d9d90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ahUfB4E4j3eJvZ5bR3G02ilm36lJwD5r\n",
            "To: /content/original_sample.wav\n",
            "100%|██████████| 1.30M/1.30M [00:00<00:00, 87.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x-AYvELvfmI_3h5bajLbECTKuPgBOBIB\n",
            "To: /content/hindi_transcript.txt\n",
            "100%|██████████| 33.6k/33.6k [00:00<00:00, 8.13MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hindi_transcript.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 0: Make the Audio compatible\n",
        "waveform, sr = torchaudio.load(\"original_sample.wav\")\n",
        "# Resample to 24kHz if needed\n",
        "resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=24000)\n",
        "resampled_waveform = resampler(waveform)\n",
        "# Convert to mono\n",
        "if resampled_waveform.shape[0] > 1:\n",
        "    resampled_waveform = resampled_waveform.mean(dim=0, keepdim=True)\n",
        "# Save in correct format\n",
        "torchaudio.save(\"voice_sample.wav\", resampled_waveform, 24000, encoding=\"PCM_S\", bits_per_sample=16)"
      ],
      "metadata": {
        "id": "oDuCO8gvFPcO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 1: Load Tortoise model\n",
        "tts = TextToSpeech()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVwUoY3FFUui",
        "outputId": "8646ac8c-8e95-43e8-c240-50e0d6251a9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Load own voice\n",
        "# Load waveform as tensor\n",
        "waveform, sr = torchaudio.load(\"voice_sample.wav\")\n",
        "if sr != 24000:\n",
        "    resample = torchaudio.transforms.Resample(orig_freq=sr, new_freq=24000)\n",
        "    waveform = resample(waveform)\n",
        "if waveform.shape[0] > 1:\n",
        "    waveform = waveform.mean(dim=0, keepdim=True)\n",
        "waveform = waveform.to(tts.device)  # Move to model's device\n",
        "voice_samples = [waveform]\n",
        "\n",
        "# Call get_conditioning_latents() with waveforms\n",
        "conditioning_latents = tts.get_conditioning_latents(voice_samples)"
      ],
      "metadata": {
        "id": "AhjckrXxFae-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Hindi text to synthesize\n",
        "# Load the translated Hindi text\n",
        "with open(\"hindi_transcript.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    hindi_text = f.read()\n",
        "\n",
        "# Step 2: Extract the first 5% of the text\n",
        "cutoff = int(len(hindi_text) * 0.05)  # 5% of total characters\n",
        "demo_text = hindi_text[:cutoff]\n",
        "\n",
        "print(f\"Using {cutoff} characters for demo:\\n\")\n",
        "print(demo_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd2-IGCJFaWX",
        "outputId": "359ff939-295e-4f0c-95b0-34cc2c7fe120"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 674 characters for demo:\n",
            "\n",
            "सब ठीक है, अंतिम वर्ग, हमने क्या चर्चा की? विंडिंग मैकेनिज्म। विंडिंग मैकेनिज्म, राइट? अब, विंडिंग तंत्र सभी प्रकार के कार्यों के लिए लागू होते हैं, है ना? क्योंकि आपके पास बड़े ऑडियो सिग्नल हैं, इसलिए आपको इसे संसाधित करने के लिए भागों, भागों, भागों में इसे तोड़ना होगा, है ना? इसलिए, विंडिंग, कर्लिंग, और अब आइए देखें कि वास्तविक कार्य क्या हैं जो हम प्रदर्शन कर सकते हैं। भाषण वृद्धि उन विषयों में से एक थी जो किसी को सूचीबद्ध करती है, है ना? तो, भाषण वृद्धि क्या है? बहुत सरल, है ना? आपके पास कोई भी ऑडियो सिग्नल विभिन्न प्रकार के शोर हो सकता है। इसलिए, भाषण वृद्धि भाषण को साफ करने, शोर को हटाने के बारे में बात करती है, जबकि यह सुनिश्चित करती है कि वास्तविक सामग्री सं\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Generate audio in own voice\n",
        "# Step 4.1: Split into smaller chunks\n",
        "segments = split_text(demo_text, max_words=40)  # adjust as needed\n",
        "# Step 4.2: Run TTS on each segment\n",
        "all_audios = []\n",
        "for i, segment in enumerate(segments):\n",
        "    print(f\"Generating segment {i+1}/{len(segments)}: {segment[:50]}...\")\n",
        "    audio = tts.tts_with_preset(\n",
        "        segment,\n",
        "        voice_samples=voice_samples,\n",
        "        conditioning_latents=conditioning_latents,\n",
        "        preset=\"fast\"\n",
        "    )\n",
        "    all_audios.append(audio)\n",
        "# Step 4.3: Concatenate all generated audio\n",
        "final_audio = torch.cat(all_audios, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrdRbPT6FaN3",
        "outputId": "3c496aca-f4ab-47fb-d6ba-29db82fe9f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating segment 1/5: सब ठीक है, अंतिम वर्ग, हमने क्या चर्चा की? विंडिंग...\n",
            "Generating autoregressive samples..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/96 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Save output\n",
        "torchaudio.save(\"M23CSA544_SU_Major-Q1_hindi_tts_own_voice.wav\", final_audio.squeeze(0).cpu(), 24000)\n",
        "print(\"TTS audio generated in own voice.\")\n",
        "# Download the transcript to Local Computer\n",
        "from google.colab import files\n",
        "files.download(\"M23CSA544_SU_Major-Q1_hindi_tts_own_voice.wav\")"
      ],
      "metadata": {
        "id": "lsLqHs90FZ_J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}